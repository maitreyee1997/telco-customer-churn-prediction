# ğŸ“‰ Telco Customer Churn Prediction App

An end-to-end Machine Learning project that predicts whether a telecom customer is likely to churn.  
The model is trained on the Telco Customer Churn dataset and optimized to improve Recall for better churn detection.

---

## ğŸ“Œ Project Overview

This project predicts whether a telecom customer will leave the company based on historical customer data.

It follows a complete Data Science workflow:

- Data Cleaning
- Exploratory Data Analysis (EDA)
- Feature Encoding
- Model Training
- Threshold Optimization
- Model Evaluation
- Model Saving
- Deployment Ready Structure

---

## ğŸ§  Problem Statement

Customer churn leads to significant revenue loss in the telecom industry.

The objective of this project is to:

- Identify high-risk customers
- Minimize missed churn cases
- Improve customer retention strategies

Unlike traditional models optimized only for accuracy, this solution focuses on improving **Recall** to reduce false negatives (missed churn customers).

---

## ğŸ“‚ Dataset Information

- Source: Kaggle â€“ Telco Customer Churn Dataset
- Records: 7000+ customers
- Features Include:
  - Customer demographics
  - Account information
  - Services subscribed
  - Monthly & Total charges
  - Contract type
  - Payment method

Target Variable:
```
Churn (Yes / No)
```

---

## âš™ï¸ Tech Stack

- Python
- Pandas
- NumPy
- Matplotlib
- Seaborn
- Scikit-Learn
- XGBoost
- Joblib

---

## ğŸ¤– Model Used

### XGBoost Classifier (Final Model)

Pipeline Steps:

1ï¸âƒ£ Data Cleaning  
2ï¸âƒ£ Label Encoding / One-Hot Encoding  
3ï¸âƒ£ Train-Test Split  
4ï¸âƒ£ Model Training  
5ï¸âƒ£ Threshold Optimization (0.3 for higher Recall)  
6ï¸âƒ£ Model Evaluation  

---

## ğŸ“Š Model Performance

- Accuracy: 82%+
- Recall: Improved using custom threshold (0.3)
- Confusion Matrix Evaluated
- Better detection of churn customers compared to default threshold

Why threshold tuning?

Instead of default 0.5 threshold, using 0.3 improves Recall â€” meaning fewer churn customers are missed.

---

## ğŸ’¾ Model Saving

The trained model is saved using:

```python
joblib.dump(model, "models/churn_model.pkl")
```

---

## ğŸš€ How to Run the Project Locally

### 1ï¸âƒ£ Clone the Repository

```
git clone <your-repo-link>
cd telco_churn_prediction
```

### 2ï¸âƒ£ Create and Activate Virtual Environment

```
conda create -n churn_env python=3.10
conda activate churn_env
```

### 3ï¸âƒ£ Install Requirements

```
pip install -r requirements.txt
```

### 4ï¸âƒ£ Run the Application (If Streamlit App Exists)

```
streamlit run application.py
```

---

## ğŸ“‚ Project Structure

```
telco_customer_churn/
â”‚
â”œâ”€â”€ data/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ churn_model.pkl
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ churn_model_training.ipynb
â”œâ”€â”€ application.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“ˆ Future Improvements

- Hyperparameter tuning
- Cross-validation
- SHAP feature importance
- Model deployment on Streamlit Cloud
- API deployment using FastAPI

---

## ğŸ‘©â€ğŸ’» Author

Maitreyee  
Data Analyst | Aspiring Data Scientist  

---

## â­ If you like this project

Give it a â­ on GitHub!
